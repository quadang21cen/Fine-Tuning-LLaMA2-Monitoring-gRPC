# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc

import llama2_pb2 as llama2__pb2


class LLamaServiceStub(object):
    """Missing associated documentation comment in .proto file."""

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.UploadImage = channel.unary_unary(
                '/llamaservice.LLamaService/UploadImage',
                request_serializer=llama2__pb2.ImageRequest.SerializeToString,
                response_deserializer=llama2__pb2.StatusResponse.FromString,
                )
        self.GetStatus = channel.unary_unary(
                '/llamaservice.LLamaService/GetStatus',
                request_serializer=llama2__pb2.EmptyRequest.SerializeToString,
                response_deserializer=llama2__pb2.StatusResponse.FromString,
                )
        self.Predict = channel.unary_unary(
                '/llamaservice.LLamaService/Predict',
                request_serializer=llama2__pb2.PredictionRequest.SerializeToString,
                response_deserializer=llama2__pb2.PredictionResponse.FromString,
                )
        self.ExportModel = channel.unary_unary(
                '/llamaservice.LLamaService/ExportModel',
                request_serializer=llama2__pb2.ModelExportRequest.SerializeToString,
                response_deserializer=llama2__pb2.StatusResponse.FromString,
                )
        self.CreateDataset = channel.unary_unary(
                '/llamaservice.LLamaService/CreateDataset',
                request_serializer=llama2__pb2.DatasetRequest.SerializeToString,
                response_deserializer=llama2__pb2.StatusResponse.FromString,
                )
        self.ViewLogs = channel.unary_unary(
                '/llamaservice.LLamaService/ViewLogs',
                request_serializer=llama2__pb2.EmptyRequest.SerializeToString,
                response_deserializer=llama2__pb2.LogResponse.FromString,
                )
        self.DownloadCheckpoint = channel.unary_unary(
                '/llamaservice.LLamaService/DownloadCheckpoint',
                request_serializer=llama2__pb2.EmptyRequest.SerializeToString,
                response_deserializer=llama2__pb2.FileResponse.FromString,
                )


class LLamaServiceServicer(object):
    """Missing associated documentation comment in .proto file."""

    def UploadImage(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GetStatus(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def Predict(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ExportModel(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def CreateDataset(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ViewLogs(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def DownloadCheckpoint(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_LLamaServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'UploadImage': grpc.unary_unary_rpc_method_handler(
                    servicer.UploadImage,
                    request_deserializer=llama2__pb2.ImageRequest.FromString,
                    response_serializer=llama2__pb2.StatusResponse.SerializeToString,
            ),
            'GetStatus': grpc.unary_unary_rpc_method_handler(
                    servicer.GetStatus,
                    request_deserializer=llama2__pb2.EmptyRequest.FromString,
                    response_serializer=llama2__pb2.StatusResponse.SerializeToString,
            ),
            'Predict': grpc.unary_unary_rpc_method_handler(
                    servicer.Predict,
                    request_deserializer=llama2__pb2.PredictionRequest.FromString,
                    response_serializer=llama2__pb2.PredictionResponse.SerializeToString,
            ),
            'ExportModel': grpc.unary_unary_rpc_method_handler(
                    servicer.ExportModel,
                    request_deserializer=llama2__pb2.ModelExportRequest.FromString,
                    response_serializer=llama2__pb2.StatusResponse.SerializeToString,
            ),
            'CreateDataset': grpc.unary_unary_rpc_method_handler(
                    servicer.CreateDataset,
                    request_deserializer=llama2__pb2.DatasetRequest.FromString,
                    response_serializer=llama2__pb2.StatusResponse.SerializeToString,
            ),
            'ViewLogs': grpc.unary_unary_rpc_method_handler(
                    servicer.ViewLogs,
                    request_deserializer=llama2__pb2.EmptyRequest.FromString,
                    response_serializer=llama2__pb2.LogResponse.SerializeToString,
            ),
            'DownloadCheckpoint': grpc.unary_unary_rpc_method_handler(
                    servicer.DownloadCheckpoint,
                    request_deserializer=llama2__pb2.EmptyRequest.FromString,
                    response_serializer=llama2__pb2.FileResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'llamaservice.LLamaService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


 # This class is part of an EXPERIMENTAL API.
class LLamaService(object):
    """Missing associated documentation comment in .proto file."""

    @staticmethod
    def UploadImage(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/llamaservice.LLamaService/UploadImage',
            llama2__pb2.ImageRequest.SerializeToString,
            llama2__pb2.StatusResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def GetStatus(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/llamaservice.LLamaService/GetStatus',
            llama2__pb2.EmptyRequest.SerializeToString,
            llama2__pb2.StatusResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def Predict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/llamaservice.LLamaService/Predict',
            llama2__pb2.PredictionRequest.SerializeToString,
            llama2__pb2.PredictionResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def ExportModel(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/llamaservice.LLamaService/ExportModel',
            llama2__pb2.ModelExportRequest.SerializeToString,
            llama2__pb2.StatusResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def CreateDataset(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/llamaservice.LLamaService/CreateDataset',
            llama2__pb2.DatasetRequest.SerializeToString,
            llama2__pb2.StatusResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def ViewLogs(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/llamaservice.LLamaService/ViewLogs',
            llama2__pb2.EmptyRequest.SerializeToString,
            llama2__pb2.LogResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def DownloadCheckpoint(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/llamaservice.LLamaService/DownloadCheckpoint',
            llama2__pb2.EmptyRequest.SerializeToString,
            llama2__pb2.FileResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
